# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzcLT8Bykp36_PjrYvhs-Ds-Um6F5D7D
"""

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9761760,"sourceType":"datasetVersion","datasetId":5977881}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:15.604594Z","iopub.execute_input":"2024-12-13T08:23:15.605116Z","iopub.status.idle":"2024-12-13T08:23:29.126424Z","shell.execute_reply.started":"2024-12-13T08:23:15.605077Z","shell.execute_reply":"2024-12-13T08:23:29.125337Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Paths to Dataset**","metadata":{}},{"cell_type":"code","source":"# Paths to the dataset\nbase_dir = '/kaggle/input/mens-and-womens-images-for-fashion-classification'\ntrain_dir = os.path.join(base_dir, 'train')\nvalid_dir = os.path.join(base_dir, 'valid')\ntest_dir = os.path.join(base_dir, 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:29.128604Z","iopub.execute_input":"2024-12-13T08:23:29.129388Z","iopub.status.idle":"2024-12-13T08:23:29.134796Z","shell.execute_reply.started":"2024-12-13T08:23:29.129338Z","shell.execute_reply":"2024-12-13T08:23:29.133862Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# **Data Augmentation and Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Data augmentation and preprocessing\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:29.135855Z","iopub.execute_input":"2024-12-13T08:23:29.136231Z","iopub.status.idle":"2024-12-13T08:23:29.166530Z","shell.execute_reply.started":"2024-12-13T08:23:29.136190Z","shell.execute_reply":"2024-12-13T08:23:29.165293Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# **Load Images**","metadata":{}},{"cell_type":"code","source":"# Load images\ntrain_data = train_datagen.flow_from_directory(train_dir, \n                                               target_size=(128, 128),\n                                               batch_size=32, \n                                               class_mode='binary')\n\nvalid_data = valid_datagen.flow_from_directory(valid_dir, \n                                               target_size=(128, 128),\n                                               batch_size=32, \n                                               class_mode='binary')\n\ntest_data = test_datagen.flow_from_directory(test_dir, \n                                             target_size=(128, 128),\n                                             batch_size=32, \n                                             class_mode='binary',\n                                             shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:29.169160Z","iopub.execute_input":"2024-12-13T08:23:29.169598Z","iopub.status.idle":"2024-12-13T08:23:30.264604Z","shell.execute_reply.started":"2024-12-13T08:23:29.169566Z","shell.execute_reply":"2024-12-13T08:23:30.263586Z"}},"outputs":[{"name":"stdout","text":"Found 850 images belonging to 2 classes.\nFound 100 images belonging to 2 classes.\nFound 50 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Model Definition**","metadata":{}},{"cell_type":"code","source":"# Model definition\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')  # Binary classification\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:30.266007Z","iopub.execute_input":"2024-12-13T08:23:30.266794Z","iopub.status.idle":"2024-12-13T08:23:30.402258Z","shell.execute_reply.started":"2024-12-13T08:23:30.266747Z","shell.execute_reply":"2024-12-13T08:23:30.401275Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **Compile the Model**","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_data,\n                    epochs=20,\n                    validation_data=valid_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T08:23:30.403400Z","iopub.execute_input":"2024-12-13T08:23:30.403677Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 697ms/step - accuracy: 0.7853 - loss: 0.5498 - val_accuracy: 0.7700 - val_loss: 0.5461\nEpoch 2/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 556ms/step - accuracy: 0.8100 - loss: 0.5026 - val_accuracy: 0.7700 - val_loss: 0.6146\nEpoch 3/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.7939 - loss: 0.5352 - val_accuracy: 0.7700 - val_loss: 0.5326\nEpoch 4/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 534ms/step - accuracy: 0.8114 - loss: 0.4876 - val_accuracy: 0.7700 - val_loss: 0.5259\nEpoch 5/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 580ms/step - accuracy: 0.7992 - loss: 0.5052 - val_accuracy: 0.7700 - val_loss: 0.5177\nEpoch 6/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 523ms/step - accuracy: 0.8251 - loss: 0.4811 - val_accuracy: 0.7700 - val_loss: 0.5365\nEpoch 7/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 553ms/step - accuracy: 0.8047 - loss: 0.5112 - val_accuracy: 0.7700 - val_loss: 0.5298\nEpoch 8/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 532ms/step - accuracy: 0.8323 - loss: 0.4423 - val_accuracy: 0.7700 - val_loss: 0.5147\nEpoch 9/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 557ms/step - accuracy: 0.8020 - loss: 0.4839 - val_accuracy: 0.7700 - val_loss: 0.5982\nEpoch 10/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 536ms/step - accuracy: 0.8342 - loss: 0.4280 - val_accuracy: 0.7700 - val_loss: 0.5095\nEpoch 11/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 563ms/step - accuracy: 0.8088 - loss: 0.4599 - val_accuracy: 0.7700 - val_loss: 0.5168\nEpoch 12/20\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 526ms/step - accuracy: 0.7993 - loss: 0.4559 - val_accuracy: 0.7700 - val_loss: 0.5478\nEpoch 13/20\n\u001b[1m17/27\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 549ms/step - accuracy: 0.8030 - loss: 0.5234","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(test_data)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Loss')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Hyperparameter Tuning using Optuna**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Function to create the model\ndef create_model(trial):\n    model = models.Sequential()\n    model.add(layers.Conv2D(trial.suggest_int('filters1', 32, 128, step=32), \n                            kernel_size=trial.suggest_categorical('kernel1', [(3, 3), (5, 5)]),\n                            activation='relu', input_shape=(128, 128, 3)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(trial.suggest_int('filters2', 64, 256, step=64), \n                            kernel_size=trial.suggest_categorical('kernel2', [(3, 3), (5, 5)]),\n                            activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(trial.suggest_int('dense_units', 64, 256, step=64), activation='relu'))\n    model.add(layers.Dropout(trial.suggest_float('dropout', 0.2, 0.5, step=0.1)))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])\n    model.compile(optimizer=optimizer, \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Objective function for Optuna**","metadata":{}},{"cell_type":"code","source":"# Objective function for Optuna\ndef objective(trial):\n    model = create_model(trial)\n    \n    # Data generators\n    train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n    valid_datagen = ImageDataGenerator(rescale=1./255)\n    \n    train_data = train_datagen.flow_from_directory(train_dir, target_size=(128, 128), batch_size=32, class_mode='binary')\n    valid_data = valid_datagen.flow_from_directory(valid_dir, target_size=(128, 128), batch_size=32, class_mode='binary')\n    \n    history = model.fit(train_data, \n                        epochs=10,  # Short epochs for faster tuning\n                        validation_data=valid_data,\n                        verbose=0)\n    \n    # Return validation accuracy\n    val_accuracy = history.history['val_accuracy'][-1]\n    return val_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Run Optuna study**","metadata":{}},{"cell_type":"code","source":"# Run Optuna study\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=20)\n\n# Best hyperparameters\nprint(\"Best Hyperparameters:\")\nprint(study.best_params)\n\n# Train final model with best hyperparameters\nbest_trial = study.best_trial\nfinal_model = create_model(best_trial)\nfinal_model.fit(train_data, \n                epochs=20, \n                validation_data=valid_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'history' contains the training history of the best model\n# Replace `history` with the variable where you stored the training history if needed\n\ndef plot_training_history(history):\n    # Extracting metrics\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(accuracy) + 1)\n\n    # Plotting accuracy\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')\n    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n\n    # Plotting loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Display plots\n    plt.tight_layout()\n    plt.show()\n\n# Call the function with the history object of your trained model\nplot_training_history(history)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Predict and Display Results**","metadata":{}},{"cell_type":"code","source":"# Predict and display results\nimport numpy as np\npredictions = (model.predict(test_data) > 0.5).astype(\"int32\")\nclasses = test_data.classes\nlabels = list(test_data.class_indices.keys())\nfor i in range(5):\n    plt.imshow(test_data[0][0][i])\n    plt.title(f\"Actual: {labels[classes[i]]}, Predicted: {labels[predictions[i][0]]}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}